{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b11d81ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah fitur terpilih: 30\n",
      "Shape data lengkap: (2768674, 30)\n",
      "Distribusi label: {1: 2242880, 0: 525794}\n"
     ]
    }
   ],
   "source": [
    "# === Cell 1: Load data dan fitur terpilih ===\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data hasil preprocessing\n",
    "X_scaled = pd.read_csv(\"../data/processed/X_scaled.csv\", dtype=\"float32\")\n",
    "y = pd.read_csv(\"../data/processed/y.csv\", dtype=\"int8\").squeeze()\n",
    "\n",
    "# Load daftar fitur terpilih\n",
    "with open(\"../data/processed/selected_features.json\") as f:\n",
    "    selected_features = json.load(f)\n",
    "\n",
    "# Ambil hanya kolom fitur terpilih\n",
    "X_selected = X_scaled[selected_features]\n",
    "\n",
    "print(f\"Jumlah fitur terpilih: {len(selected_features)}\")\n",
    "print(f\"Shape data lengkap: {X_selected.shape}\")\n",
    "print(f\"Distribusi label: {y.value_counts().to_dict()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c3cdd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1771951, 30), Val: (442988, 30), Test: (553735, 30)\n"
     ]
    }
   ],
   "source": [
    "# === Cell 2: Split data train/val/test ===\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X_selected, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.2, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3df92bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1435443, number of negative: 336508\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.129585 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6512\n",
      "[LightGBM] [Info] Number of data points in the train set: 1771951, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810092 -> initscore=1.450607\n",
      "[LightGBM] [Info] Start training from score 1.450607\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[320]\tvalid_0's binary_logloss: 0.0011987\n",
      "✅ Training selesai\n"
     ]
    }
   ],
   "source": [
    "# === Cell 3: Train model LightGBM ===\n",
    "\n",
    "from lightgbm import LGBMClassifier, early_stopping\n",
    "\n",
    "lgbm = LGBMClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lgbm.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric=\"binary_logloss\",\n",
    "    callbacks=[early_stopping(stopping_rounds=50, verbose=True)]\n",
    ")\n",
    "\n",
    "print(\"✅ Training selesai\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80e84200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.9999843791535619\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9986    0.9995    0.9990    105159\n",
      "           1     0.9999    0.9997    0.9998    448576\n",
      "\n",
      "    accuracy                         0.9996    553735\n",
      "   macro avg     0.9992    0.9996    0.9994    553735\n",
      "weighted avg     0.9996    0.9996    0.9996    553735\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[105102     57]\n",
      " [   150 448426]]\n"
     ]
    }
   ],
   "source": [
    "# === Cell 4: Evaluasi dasar ===\n",
    "\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "\n",
    "y_pred = lgbm.predict(X_test)\n",
    "y_prob = lgbm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_prob))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3204e21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.20.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b054fa73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train probs shape: (1771951,), Val probs shape: (442988,)\n"
     ]
    }
   ],
   "source": [
    "# === Cell 5: Siapkan data distillation ===\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "\n",
    "# Target: probabilitas dari LightGBM\n",
    "train_probs = lgbm.predict_proba(X_train)[:, 1]\n",
    "val_probs = lgbm.predict_proba(X_val)[:, 1]\n",
    "\n",
    "print(f\"Train probs shape: {train_probs.shape}, Val probs shape: {val_probs.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ee62aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1436\n",
      "Epoch 1: val_loss improved from None to 0.06254, saving model to student_best.keras\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 0.1031 - val_loss: 0.0625 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0665\n",
      "Epoch 2: val_loss improved from 0.06254 to 0.05992, saving model to student_best.keras\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 0.0651 - val_loss: 0.0599 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m431/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0627\n",
      "Epoch 3: val_loss improved from 0.05992 to 0.05982, saving model to student_best.keras\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0626 - val_loss: 0.0598 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m431/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0616\n",
      "Epoch 4: val_loss improved from 0.05982 to 0.05808, saving model to student_best.keras\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.0610 - val_loss: 0.0581 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0602\n",
      "Epoch 5: val_loss did not improve from 0.05808\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0607 - val_loss: 0.0620 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m432/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0607\n",
      "Epoch 6: val_loss did not improve from 0.05808\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0602 - val_loss: 0.0585 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m429/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0593\n",
      "Epoch 7: val_loss did not improve from 0.05808\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0596 - val_loss: 0.0584 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m431/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0594\n",
      "Epoch 8: val_loss did not improve from 0.05808\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - loss: 0.0602 - val_loss: 0.0588 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0595\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.05808\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0592 - val_loss: 0.0582 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0590\n",
      "Epoch 10: val_loss improved from 0.05808 to 0.05781, saving model to student_best.keras\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0589 - val_loss: 0.0578 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0585\n",
      "Epoch 11: val_loss improved from 0.05781 to 0.05752, saving model to student_best.keras\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0586 - val_loss: 0.0575 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m431/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0586\n",
      "Epoch 12: val_loss improved from 0.05752 to 0.05728, saving model to student_best.keras\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0587 - val_loss: 0.0573 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m432/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0585\n",
      "Epoch 13: val_loss did not improve from 0.05728\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.0586 - val_loss: 0.0577 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m432/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0588\n",
      "Epoch 14: val_loss improved from 0.05728 to 0.05715, saving model to student_best.keras\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0587 - val_loss: 0.0572 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m430/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0679\n",
      "Epoch 15: val_loss improved from 0.05715 to 0.05360, saving model to student_best.keras\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.0771 - val_loss: 0.0536 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m431/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0590\n",
      "Epoch 16: val_loss did not improve from 0.05360\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.0579 - val_loss: 0.0561 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m431/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0571\n",
      "Epoch 17: val_loss did not improve from 0.05360\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0572 - val_loss: 0.0564 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m431/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0588\n",
      "Epoch 18: val_loss did not improve from 0.05360\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.0663 - val_loss: 0.0835 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m430/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0817\n",
      "Epoch 19: val_loss did not improve from 0.05360\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0797 - val_loss: 0.0641 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m431/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0686\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.05360\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.0765 - val_loss: 0.0828 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m431/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0820\n",
      "Epoch 21: val_loss did not improve from 0.05360\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 0.0819 - val_loss: 0.0825 - learning_rate: 2.5000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m431/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0800\n",
      "Epoch 22: val_loss did not improve from 0.05360\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.0767 - val_loss: 0.0642 - learning_rate: 2.5000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m431/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0605\n",
      "Epoch 23: val_loss improved from 0.05360 to 0.05123, saving model to student_best.keras\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0556 - val_loss: 0.0512 - learning_rate: 2.5000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m430/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0503\n",
      "Epoch 24: val_loss did not improve from 0.05123\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.0502 - val_loss: 0.0549 - learning_rate: 2.5000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m431/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0512\n",
      "Epoch 25: val_loss did not improve from 0.05123\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0509 - val_loss: 0.0541 - learning_rate: 2.5000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0622\n",
      "Epoch 26: val_loss did not improve from 0.05123\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0681 - val_loss: 0.0666 - learning_rate: 2.5000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m432/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0678\n",
      "Epoch 27: val_loss did not improve from 0.05123\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0662 - val_loss: 0.0637 - learning_rate: 2.5000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m432/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0602\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.05123\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.0597 - val_loss: 0.0628 - learning_rate: 2.5000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m432/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0593\n",
      "Epoch 29: val_loss did not improve from 0.05123\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.0580 - val_loss: 0.0558 - learning_rate: 1.2500e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0529\n",
      "Epoch 30: val_loss improved from 0.05123 to 0.04083, saving model to student_best.keras\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0504 - val_loss: 0.0408 - learning_rate: 1.2500e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m432/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0466\n",
      "Epoch 31: val_loss did not improve from 0.04083\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0481 - val_loss: 0.0557 - learning_rate: 1.2500e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m431/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0524\n",
      "Epoch 32: val_loss did not improve from 0.04083\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0501 - val_loss: 0.0450 - learning_rate: 1.2500e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m430/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0450\n",
      "Epoch 33: val_loss improved from 0.04083 to 0.02125, saving model to student_best.keras\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 0.0443 - val_loss: 0.0212 - learning_rate: 1.2500e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m432/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0439\n",
      "Epoch 34: val_loss did not improve from 0.02125\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 19ms/step - loss: 0.0436 - val_loss: 0.0230 - learning_rate: 1.2500e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0445\n",
      "Epoch 35: val_loss did not improve from 0.02125\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0459 - val_loss: 0.0515 - learning_rate: 1.2500e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m430/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0460\n",
      "Epoch 36: val_loss did not improve from 0.02125\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.0449 - val_loss: 0.0345 - learning_rate: 1.2500e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m432/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0422\n",
      "Epoch 37: val_loss did not improve from 0.02125\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0420 - val_loss: 0.0237 - learning_rate: 1.2500e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0454\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.02125\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0469 - val_loss: 0.0539 - learning_rate: 1.2500e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m432/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0473\n",
      "Epoch 39: val_loss did not improve from 0.02125\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0472 - val_loss: 0.0510 - learning_rate: 6.2500e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0456\n",
      "Epoch 40: val_loss did not improve from 0.02125\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0459 - val_loss: 0.0530 - learning_rate: 6.2500e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0476\n",
      "Epoch 41: val_loss did not improve from 0.02125\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0484 - val_loss: 0.0538 - learning_rate: 6.2500e-05\n",
      "Epoch 42/50\n",
      "\u001b[1m431/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0483\n",
      "Epoch 42: val_loss did not improve from 0.02125\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 23ms/step - loss: 0.0489 - val_loss: 0.0543 - learning_rate: 6.2500e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m431/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0486\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.02125\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - loss: 0.0472 - val_loss: 0.0492 - learning_rate: 6.2500e-05\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "✅ Training selesai. Model disimpan ke student_best.keras\n"
     ]
    }
   ],
   "source": [
    "# === Cell 6: Train student model (Distillation Stabil & Akurat) ===\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Data float32\n",
    "X_train_np = X_train.astype(\"float32\").to_numpy()\n",
    "X_val_np = X_val.astype(\"float32\").to_numpy()\n",
    "y_train_soft = train_probs.astype(\"float32\")\n",
    "y_val_soft = val_probs.astype(\"float32\")\n",
    "\n",
    "# Temperatur scaling untuk melunakkan label\n",
    "T = 2.5\n",
    "y_train_soft_T = np.clip(y_train_soft, 1e-6, 1-1e-6) ** (1/T)\n",
    "y_val_soft_T = np.clip(y_val_soft, 1e-6, 1-1e-6) ** (1/T)\n",
    "\n",
    "# Model student (lebih stabil & dalam sedikit)\n",
    "student = Sequential([\n",
    "    Input(shape=(X_train_np.shape[1],), dtype=\"float32\"),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "student.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='mean_squared_error'  # cocok untuk meniru probabilitas teacher\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1),\n",
    "    ModelCheckpoint(\"student_best.keras\", save_best_only=True, monitor='val_loss', verbose=1)\n",
    "]\n",
    "\n",
    "history = student.fit(\n",
    "    X_train_np, y_train_soft_T,\n",
    "    validation_data=(X_val_np, y_val_soft_T),\n",
    "    batch_size=4096,\n",
    "    epochs=50,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "print(\"✅ Training selesai. Model disimpan ke student_best.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4329bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "ROC-AUC: 0.9432123398625232\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9826    0.8902    0.9341    105159\n",
      "           1     0.9748    0.9963    0.9854    448576\n",
      "\n",
      "    accuracy                         0.9761    553735\n",
      "   macro avg     0.9787    0.9432    0.9598    553735\n",
      "weighted avg     0.9763    0.9761    0.9757    553735\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 93609  11550]\n",
      " [  1662 446914]]\n"
     ]
    }
   ],
   "source": [
    "# === Cell 7: Evaluasi student vs teacher ===\n",
    "y_student_prob = student.predict(X_test.astype(\"float32\"), batch_size=2048).squeeze()\n",
    "y_student_pred = (y_student_prob > 0.5).astype(int)\n",
    "\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_student_prob))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_student_pred, digits=4))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_student_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31039760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model berhasil disimpan ke: ../models\\lgbm_student.keras\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "\n",
    "# === Pengaturan ===\n",
    "old_model_path = \"student_best.keras\"          # model lama hasil training\n",
    "new_model_dir  = \"../models\"                   # folder tujuan (sudah kamu buat di GitHub)\n",
    "new_model_name = \"lgbm_student.keras\" # nama baru model\n",
    "\n",
    "# === Buat folder kalau belum ada ===\n",
    "os.makedirs(new_model_dir, exist_ok=True)\n",
    "\n",
    "# === Load model lama ===\n",
    "model = load_model(old_model_path)\n",
    "\n",
    "# === Simpan ulang ke folder baru ===\n",
    "new_model_path = os.path.join(new_model_dir, new_model_name)\n",
    "model.save(new_model_path)\n",
    "\n",
    "print(f\"✅ Model berhasil disimpan ke: {new_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7df257d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\BINTAN~1\\AppData\\Local\\Temp\\tmpxy6gyykz\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\BINTAN~1\\AppData\\Local\\Temp\\tmpxy6gyykz\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\BINTAN~1\\AppData\\Local\\Temp\\tmpxy6gyykz'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 30), dtype=tf.float32, name='input_layer_2')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2214486459488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2214486170208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2214486500880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2214486496832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2214486500704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2214486506688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2214484119744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2214484120448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "✅ Model berhasil dikonversi ke format TFLite: ../models/lgbm_student.tflite\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load model hasil training\n",
    "model = tf.keras.models.load_model(\"../models/lgbm_student.keras\")\n",
    "\n",
    "# Konversi ke TensorFlow Lite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# (Opsional) optimasi ukuran file agar ringan di deployment\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# Jalankan konversi\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Simpan hasil konversi ke folder yang sama\n",
    "with open(\"../models/lgbm_student.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"✅ Model berhasil dikonversi ke format TFLite: ../models/lgbm_student.tflite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "132d2796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Input Tensor ===\n",
      "[{'name': 'serving_default_input_layer_2:0', 'index': 0, 'shape': array([ 1, 30], dtype=int32), 'shape_signature': array([-1, 30], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "\n",
      "=== Output Tensor ===\n",
      "[{'name': 'StatefulPartitionedCall_1:0', 'index': 13, 'shape': array([1, 1], dtype=int32), 'shape_signature': array([-1,  1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BINTANG PANDU\\IPS+ML\\CICIDS2017---IPSML\\venv310\\lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    }
   ],
   "source": [
    "# Verifikasi arsitektur model TFLite\n",
    "interpreter = tf.lite.Interpreter(model_path=\"../models/lgbm_student.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(\"=== Input Tensor ===\")\n",
    "print(input_details)\n",
    "print(\"\\n=== Output Tensor ===\")\n",
    "print(output_details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac775ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output prediksi: [[1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=\"../models/lgbm_student.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Ambil detail tensor\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Buat dummy data (1 sampel, 30 fitur)\n",
    "dummy_input = np.random.rand(1, 30).astype(np.float32)\n",
    "\n",
    "# Jalankan inferensi\n",
    "interpreter.set_tensor(input_details[0]['index'], dummy_input)\n",
    "interpreter.invoke()\n",
    "prediction = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "print(\"Output prediksi:\", prediction)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
